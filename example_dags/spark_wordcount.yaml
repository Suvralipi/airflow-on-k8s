apiVersion: "sparkoperator.hpe.com/v1beta2"
kind: SparkApplication
metadata:
  name: pyspark-wordcount-secure
  namespace: mlops
spec:
  sparkConf:
    # Note: If you are executing the application as a K8 user that MapR can verify,
    #       you do not need to specify a spark.mapr.user.secret
    #spark.mapr.user.secret: spark-user-secret
    # Note: You do not need to specify a spark.eventLog.dir
    #       it will be auto-generated with the pattern "maprfs:///apps/spark/<namespace>"
    #spark.eventLog.dir: "maprfs:///apps/spark/sampletenant"
    spark.hadoop.fs.dtap.impl: "com.bluedata.hadoop.bdfs.Bdfs"
    spark.hadoop.fs.AbstractFileSystem.dtap.impl: "com.bluedata.hadoop.bdfs.BdAbstractFS"
    spark.hadoop.fs.dtap.impl.disable.cache: "false" 
    spark.driver.extraClassPath: "local:///opt/bdfs/bluedata-dtap.jar"
    spark.executor.extraClassPath: "local:///opt/bdfs/bluedata-dtap.jar"
  type: Python
  sparkVersion: 2.4.7
  pythonVersion: "3"
  mode: cluster
  image: gcr.io/mapr-252711/spark-py-2.4.7:202104010902C
  imagePullPolicy: Always
  mainApplicationFile: local:///opt/mapr/spark/spark-2.4.7/examples/src/main/python/wordcount.py
  restartPolicy:
    type: Never
  arguments:
  - dtap://TenantStorage/data/wordcount.txt
  imagePullSecrets:
  - imagepull
  driver:
    cores: 1
    coreLimit: "1000m"
    memory: "512m"
    labels:
      version: 2.4.7
      hpecp.hpe.com/dtap: hadoop2
    # Note: You do not need to specify a serviceAccount
    #       it will be auto-generated referencing the pre-existing "hpe-<namespace>"
    #serviceAccount: hpe-sampletenant
  executor:
    cores: 1
    coreLimit: "1000m"
    instances: 2
    memory: "512m"
    labels:
      version: 2.4.7
      hpecp.hpe.com/dtap: hadoop2